{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit ('tora': conda)",
   "metadata": {
    "interpreter": {
     "hash": "94d8f3d174e65e48f1a5525808dadd7487dea75e246905fc1f2358aeec59b2cc"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f89fa252330>"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [(\"me gusta comer en la cafeteria\".split(), \"SPANISH\"),\n",
    "        (\"Give it to me\".split(), \"ENGLISH\"),\n",
    "        (\"No creo que sea una buena idea\".split(), \"SPANISH\"),\n",
    "        (\"No it is not a good idea to get lost at sea\".split(), \"ENGLISH\")]\n",
    "\n",
    "test_data = [(\"Yo creo que si\".split(), \"SPANISH\"),\n",
    "             (\"it is lost on me\".split(), \"ENGLISH\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[   ('me', 0),\n    ('gusta', 1),\n    ('comer', 2),\n    ('en', 3),\n    ('la', 4),\n    ('cafeteria', 5),\n    ('Give', 6),\n    ('it', 7),\n    ('to', 8),\n    ('No', 9),\n    ('creo', 10),\n    ('que', 11),\n    ('sea', 12),\n    ('una', 13),\n    ('buena', 14),\n    ('idea', 15),\n    ('is', 16),\n    ('not', 17),\n    ('a', 18),\n    ('good', 19),\n    ('get', 20),\n    ('lost', 21),\n    ('at', 22),\n    ('Yo', 23),\n    ('si', 24),\n    ('on', 25)]\n"
     ]
    }
   ],
   "source": [
    "word_to_idx={}\n",
    "for feat,label in train_data+test_data:\n",
    "    for word in feat:\n",
    "        if  word not in word_to_idx:\n",
    "            word_to_idx[word]=len(word_to_idx)\n",
    "\n",
    "pprint(sorted(word_to_idx.items(),key=lambda x : x[1]), indent=4)\n",
    "\n",
    "VOCAB_SIZE = len(word_to_idx)\n",
    "NUM_LABELS = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoWClassifier(nn.Module):\n",
    "    def __init__(self,num_labels,vocab_size):\n",
    "        #or put it this way \n",
    "        #super(BowClassifier,self).__init__()\n",
    "        super().__init__() \n",
    "\n",
    "        self.linear = nn.Linear(vocab_size,num_labels)\n",
    "\n",
    "    def forward(self,bow_vec):\n",
    "        #data points in form of row vectors\n",
    "        return F.log_softmax(self.linear(bow_vec),1) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bow_vector(sentence, word_to_idx):\n",
    "\n",
    "    vec = torch.zeros(len(word_to_idx))\n",
    "    \n",
    "    for word in sentence:\n",
    "        #one hot encoding vector\n",
    "        vec[word_to_idx[word]]+=1\n",
    "\n",
    "    return vec.view(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_target(label, label_to_idx):\n",
    "    return torch.LongTensor([label_to_idx[label]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BoWClassifier(NUM_LABELS,VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Parameter containing:\ntensor([[ 0.1011, -0.0866, -0.0380,  0.0921, -0.1846,  0.1176, -0.0403,  0.0998,\n          0.0273, -0.0240,  0.0544,  0.0097,  0.0716, -0.0764, -0.0143, -0.0177,\n          0.0284, -0.0008,  0.1714,  0.0610, -0.0730, -0.1184, -0.0329, -0.0846,\n         -0.0628,  0.0094],\n        [ 0.1169,  0.1066, -0.1917,  0.1216,  0.0548,  0.1860,  0.1294, -0.1787,\n         -0.1865, -0.0946,  0.1722, -0.0327,  0.0839, -0.0911,  0.1924, -0.0830,\n          0.1471,  0.0023, -0.1033,  0.1008, -0.1041,  0.0577, -0.0566, -0.0215,\n         -0.1885, -0.0935]], requires_grad=True)\nParameter containing:\ntensor([ 0.1064, -0.0477], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['me', 'gusta', 'comer', 'en', 'la', 'cafeteria']\ntensor([[1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0.]])\ntensor([[-0.8195, -0.5810]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    sample = train_data[0]\n",
    "    print(sample[0])\n",
    "    bow_vector = make_bow_vector(sample[0], word_to_idx)\n",
    "    pprint(bow_vector)\n",
    "    log_probs= model(bow_vector)\n",
    "    pprint(log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_idx = {\"SPANISH\": 0, \"ENGLISH\": 1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[-0.6250, -0.7662]])\ntensor([[-0.5870, -0.8119]])\n"
     ]
    }
   ],
   "source": [
    "#before training .\n",
    "with torch.no_grad():\n",
    "    for feat, label in test_data:\n",
    "        bow_vec = make_bow_vector(feat, word_to_idx)\n",
    "        log_probs = model(bow_vec)\n",
    "        print(log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([-0.0143,  0.1924], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(next(model.parameters())[: ,word_to_idx['buena']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparams\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(100):\n",
    "    for instance,label in train_data:\n",
    "\n",
    "        #pytorch needs to clean up the left over gradients \n",
    "        model.zero_grad()\n",
    "\n",
    "        #making one hot word embedding vectors and string labels into ints\n",
    "        bow_vec = make_bow_vector(instance, word_to_idx)\n",
    "        target = make_target(label,label_to_idx)\n",
    "\n",
    "        #forward pass\n",
    "        log_probs = model(bow_vec)\n",
    "\n",
    "        #computing loss fn based on predicted and target\n",
    "        loss = loss_function(log_probs,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([[-0.1210, -2.1721]])\ntensor([[-2.7767, -0.0643]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for feat, label in test_data:\n",
    "        bow_vec = make_bow_vector(feat,word_to_idx)\n",
    "        log_probs = model(bow_vec)\n",
    "        print(log_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([ 0.4318, -0.2536], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(next(model.parameters())[: ,word_to_idx['buena']])\n",
    "#this output shows improvement in the suggestion that this belongs to spanish indeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}